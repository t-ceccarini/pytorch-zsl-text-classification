{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis_twitter.ipynb","provenance":[],"collapsed_sections":["YPISafRuZUK3","RLWceP3n3eLT","ssKH6o0e3r2y","PHtGPyts5fKM","38dUQJn75ICC","GlAkn84q47h_"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"66011446a51d4017987d49fa37549952":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_82f9dc83c7044a5da6148a5514a2c75f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bb44b1f3b26645928cd89d37f072a74f","IPY_MODEL_8b7c9255194a4f6b8bcd9f6ce9e4b4ad","IPY_MODEL_a4e1245d3d6946db9580f4dbc25c7b49"]}},"82f9dc83c7044a5da6148a5514a2c75f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb44b1f3b26645928cd89d37f072a74f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee0930c07dee43b1b6a0e04183f01ab3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f1707e624c24adeb547180294185ca0"}},"8b7c9255194a4f6b8bcd9f6ce9e4b4ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_360aae05dbdb48f1976e30050121c056","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1420,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1420,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2679c193580b47e4acd7ba4cf08122f4"}},"a4e1245d3d6946db9580f4dbc25c7b49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_77ad24d42c9c4913b8ccd8fce3c1c92f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3.20k/? [00:00&lt;00:00, 61.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6627ef562a2b4f6681280fa1e6e5624f"}},"ee0930c07dee43b1b6a0e04183f01ab3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f1707e624c24adeb547180294185ca0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"360aae05dbdb48f1976e30050121c056":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2679c193580b47e4acd7ba4cf08122f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77ad24d42c9c4913b8ccd8fce3c1c92f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6627ef562a2b4f6681280fa1e6e5624f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"298fc44a495448658c036d084cf9bffa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_44fdfc9473584aa6873aed33d9d66be9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_335d51a8bdb348d7955276894ed6995e","IPY_MODEL_5ebf3f9600d34afaa80bd3ec95c696d7","IPY_MODEL_72db15492a1e43e19749cbdb4fdae7bc"]}},"44fdfc9473584aa6873aed33d9d66be9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"335d51a8bdb348d7955276894ed6995e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b3bf1f059964864a5a8966f02879510","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f26a55907664f2fa828a152d37f178f"}},"5ebf3f9600d34afaa80bd3ec95c696d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6b7b718aa0c14065abe7390bc5bdbbda","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2069,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2069,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7905c052029b4a72a27dd901cf1514ae"}},"72db15492a1e43e19749cbdb4fdae7bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a17f948c1f314011b74a65f7eb1bde18","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.29k/? [00:00&lt;00:00, 139kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_915cd4f21b4e462e9cd054f00732edde"}},"4b3bf1f059964864a5a8966f02879510":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f26a55907664f2fa828a152d37f178f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b7b718aa0c14065abe7390bc5bdbbda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7905c052029b4a72a27dd901cf1514ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a17f948c1f314011b74a65f7eb1bde18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"915cd4f21b4e462e9cd054f00732edde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed8353f0b5cc4be3a7ea433a49078196":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73801364b99a4bf6bf348744f5102de1","IPY_MODEL_7108c2cc115b445db02816f392b736d9","IPY_MODEL_aa98d81fab344268b23add3112e31931"],"layout":"IPY_MODEL_06f9a05fcdd94dbcab3e8599f483afd4"}},"73801364b99a4bf6bf348744f5102de1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b2aa8834e249679ba167c4c06ce258","placeholder":"​","style":"IPY_MODEL_fa54e73fde30449fb95824b8b708392f","value":"Downloading: 100%"}},"7108c2cc115b445db02816f392b736d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b27d14fc1a00434abf5e3d8600da4302","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a7e27e70dc64da4b058e0b690cd84a6","value":625}},"aa98d81fab344268b23add3112e31931":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_768468e0523a4393bebe45ea7728416d","placeholder":"​","style":"IPY_MODEL_fdf88b1b70bc4e828d8aae1443461723","value":" 625/625 [00:00&lt;00:00, 13.9kB/s]"}},"06f9a05fcdd94dbcab3e8599f483afd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b2aa8834e249679ba167c4c06ce258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa54e73fde30449fb95824b8b708392f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b27d14fc1a00434abf5e3d8600da4302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7e27e70dc64da4b058e0b690cd84a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"768468e0523a4393bebe45ea7728416d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdf88b1b70bc4e828d8aae1443461723":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9be802c08d8b4f3293285a2609b0215f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70ec195a2dbd471d828f3c6426b23449","IPY_MODEL_fd5e8f5ae68d40d4a6b7b04d10aa48f1","IPY_MODEL_b9598a5d503d481992ce947f19bdb5d9"],"layout":"IPY_MODEL_c253dc9f840642dbb4b15bceb4a22125"}},"70ec195a2dbd471d828f3c6426b23449":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_747aef9b9aea445fa2ee05504c5792e0","placeholder":"​","style":"IPY_MODEL_14fde2e40a724315b36fcd35dbc648d6","value":"Downloading: 100%"}},"fd5e8f5ae68d40d4a6b7b04d10aa48f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad31ff41a554967b3565e2f5541f68c","max":1108715,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18f24fa5878f4f09bd3bd31b98a9b532","value":1108715}},"b9598a5d503d481992ce947f19bdb5d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be6c3e1b95cc43a597a6dfff6c7e286c","placeholder":"​","style":"IPY_MODEL_d0b51467f98143cfb8513e560b82ee6b","value":" 1.06M/1.06M [00:00&lt;00:00, 2.91MB/s]"}},"c253dc9f840642dbb4b15bceb4a22125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"747aef9b9aea445fa2ee05504c5792e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14fde2e40a724315b36fcd35dbc648d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad31ff41a554967b3565e2f5541f68c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f24fa5878f4f09bd3bd31b98a9b532":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be6c3e1b95cc43a597a6dfff6c7e286c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0b51467f98143cfb8513e560b82ee6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8425da9d34541fbb5d74ddffaea20ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a66f11ed9b243fd853a1493852e9119","IPY_MODEL_f9956895145d49318cb6f86a7a3878cf","IPY_MODEL_c0f6e6bca578455d8672dc7bb2b7bf3f"],"layout":"IPY_MODEL_b02e1c9a58d34864b7174ac4beba8b91"}},"0a66f11ed9b243fd853a1493852e9119":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c56d0ecfe73490399b442bd81c68cf9","placeholder":"​","style":"IPY_MODEL_72f52216d1fa4244bef724efd54b316c","value":"Downloading: 100%"}},"f9956895145d49318cb6f86a7a3878cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bde39752e0c44ecbe6bcb43b1f02dc6","max":740314266,"min":0,"orientation":"horizontal","style":"IPY_MODEL_44b4730f75e1455ebd06a4966f2bc94a","value":740314266}},"c0f6e6bca578455d8672dc7bb2b7bf3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09a1c4a30724bacbcf2b3f7115b92f0","placeholder":"​","style":"IPY_MODEL_e65882bbf9c043d78d2d007efc71e52e","value":" 706M/706M [00:16&lt;00:00, 41.0MB/s]"}},"b02e1c9a58d34864b7174ac4beba8b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c56d0ecfe73490399b442bd81c68cf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72f52216d1fa4244bef724efd54b316c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bde39752e0c44ecbe6bcb43b1f02dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44b4730f75e1455ebd06a4966f2bc94a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b09a1c4a30724bacbcf2b3f7115b92f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e65882bbf9c043d78d2d007efc71e52e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Sentiment Analysis on Italian Tweets\n","In this tutorial we'll be building a machine learning model for the sentiment analysis of italian tweets. Further details on the sentipolc dataset used can be found [here](http://www.di.unito.it/~tutreeb/sentipolc-evalita16/sentipolc-guidelines2016UPDATED130916.pdf). We'll focus only on the polarity classification task."],"metadata":{"id":"Zx21VkJAC9Pq"}},{"cell_type":"markdown","metadata":{"id":"Lf22crFfYvOA"},"source":["Upload the datasets on Google Drive and execute the next cell.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wtfzgDPYTWC","executionInfo":{"status":"ok","timestamp":1656085221288,"user_tz":-120,"elapsed":15654,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"4c2bc489-40b2-4ed7-d5ae-7c23b4b86f63"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"YPISafRuZUK3"},"source":["## Install dependencies and import libraries"]},{"cell_type":"code","metadata":{"id":"PKbzH9zYZTD2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656085242368,"user_tz":-120,"elapsed":20171,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"286dcd7d-247a-45be-a02c-a9eb1878092c"},"source":["# Transformers installation\n","! pip install transformers datasets --quiet\n","# To install from source instead of the last release, comment the command above and uncomment the following one.\n","# ! pip install git+https://github.com/huggingface/transformers.git\n","\n","# Ekphrasis installation for datasets preprocessing\n","# ! pip install ekphrasis --quiet\n","! pip install git+https://github.com/fucaja/ekphrasis.git --quiet"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.4 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 362 kB 76.4 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 60.2 MB/s \n","\u001b[K     |████████████████████████████████| 101 kB 10.4 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 70.1 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 55.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 24.0 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 54.5 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 72.7 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 4.3 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 70.6 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 72.4 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 45 kB 2.3 MB/s \n","\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n","\u001b[?25h  Building wheel for ekphrasis (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"lblrObbP6KKg","executionInfo":{"status":"ok","timestamp":1656085251660,"user_tz":-120,"elapsed":9300,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["# Import libraries\n","\n","# Preprocessing the datasets\n","import pandas as pd\n","import numpy as np\n","import torch\n","import os\n","import re\n","from ekphrasis.classes.preprocessor import TextPreProcessor\n","from ekphrasis.classes.tokenizer import SocialTokenizer\n","from ekphrasis.dicts.emoticons import emoticons\n","from ekphrasis.classes.segmenter import Segmenter\n","\n","# Define the model\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n","import torch.nn as nn\n","\n","# Pre-training function with Pytorch\n","from torch.utils.data import DataLoader\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Fine-tuning with Trainer\n","from transformers import Trainer, TrainingArguments\n","from datasets import load_metric\n","\n","# Zip and download results \n","from google.colab import files"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFJfWMe-E_Vp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656085252274,"user_tz":-120,"elapsed":620,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"d96c17b4-f1ba-4d01-ae44-d306cee57225"},"source":["# Clone ekphrasis repo\n","!git clone https://github.com/cbaziotis/ekphrasis.git"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ekphrasis'...\n","remote: Enumerating objects: 471, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (20/20), done.\u001b[K\n","remote: Total 471 (delta 15), reused 24 (delta 12), pack-reused 439\u001b[K\n","Receiving objects: 100% (471/471), 666.67 KiB | 4.60 MiB/s, done.\n","Resolving deltas: 100% (283/283), done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"RLWceP3n3eLT"},"source":["## Preprocessing the datasets"]},{"cell_type":"code","metadata":{"id":"1t9Py2HJZip-","executionInfo":{"status":"ok","timestamp":1656085261109,"user_tz":-120,"elapsed":548,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["train_df = pd.read_csv(r'/content/gdrive/MyDrive/training_set_sentipolc16.csv')\n","#train_df = pd.read_csv(r'/content/eda_train_data.csv', sep='\\t', names=[\"polarity\",\"text\"])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ex22WL5OTmDc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656085264058,"user_tz":-120,"elapsed":558,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"21c09787-61fd-44fe-e8df-e30f64d2a9fe"},"source":["#test_df = pd.read_csv(r'/content/gdrive/MyDrive/test_set_sentipolc16_gold2000.csv', sep='delimiter', engine='python', names=[\"idtwitter\",\"subj\",\"opos\",\"oneg\",\"iro\",\"lpos\",\"lneg\",\"top\",\"text\"])\n","test_df = pd.read_csv(r'/content/gdrive/MyDrive/test_set_sentipolc16_gold2000.csv', error_bad_lines=False, names=[\"idtwitter\",\"subj\",\"opos\",\"oneg\",\"iro\",\"lpos\",\"lneg\",\"top\",\"text\"])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Jdwy8HfhkLQF"},"source":["In order to train the model, we'll create the column 'polarity' based on the two columns 'opos' and 'oneg' as follows:\n","\n","| opos | oneg | polarity | label    |\n","|------|------|----------|----------|\n","|   1  |   0  |     0    | Positive |\n","|   0  |   1  |     1    | Negative |\n","|   1  |   1  |     2    | Mixed    |\n","|   0  |   0  |     3    | Neutral  |\n"]},{"cell_type":"code","metadata":{"id":"uq1qxsqBj-_X","executionInfo":{"status":"ok","timestamp":1656085387189,"user_tz":-120,"elapsed":203,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["# Create a list of conditions\n","def create_conditions(df):\n","    conditions = [\n","    (df['opos'] == 1) & (df['oneg'] == 0),\n","    (df['opos'] == 0) & (df['oneg'] == 1),\n","    (df['opos'] == 1) & (df['oneg'] == 1),\n","    (df['opos'] == 0) & (df['oneg'] == 0)\n","    ]\n","    return conditions\n","\n","# Create a list of the values we want to assign for each condition\n","polarities = [0, 1, 2, 3]\n","\n","# Create column polarity and use np.select to assign values to it using our lists as arguments\n","train_df['polarity'] = np.select(create_conditions(train_df), polarities)\n","test_df['polarity'] = np.select(create_conditions(test_df), polarities)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZERnogAJ7CDX"},"source":["# Make text lowercase\n","#train_df['text'] = train_df['text'].str.lower()\n","#test_df['text'] = test_df['text'].str.lower()\n","\n","#train_df['text'] = train_df['text'].str.replace('[^\\w\\s]','')\n","#test_df['text'] = test_df['text'].str.replace('[^\\w\\s]','')\n","\n","#train_df['text'] = train_df['text'].str.replace(',','')\n","#test_df['text'] = test_df['text'].str.replace(',','')\n","\n","#train_df['text'] = train_df['text'].str.replace('.','')\n","#test_df['text'] = test_df['text'].str.replace('.','')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bjvwWM3u4thf"},"source":["# Select only positive and negative polarity (use num_labels=2 in this case)\n","#train_df = train_df.loc[(train_df['polarity'] == 0) | (train_df['polarity'] == 1)]\n","#test_df = test_df.loc[(test_df['polarity'] == 0) | (test_df['polarity'] == 1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfpNP-NinUHl","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1656085391048,"user_tz":-120,"elapsed":193,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"d15f792b-a3d7-4a51-88be-8ac1ef310946"},"source":["# Display DataFrame with the new column\n","train_df"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               idtwitter  subj  opos  oneg  iro  lpos  lneg  top  \\\n","0     122449983151669248     1     0     1    0     0     1    1   \n","1     125485104863780865     1     0     1    0     0     1    1   \n","2     125513454315507712     1     0     1    0     0     1    1   \n","3     125524238290522113     1     0     1    0     0     1    1   \n","4     125527933224886272     1     0     1    0     0     1    1   \n","...                  ...   ...   ...   ...  ...   ...   ...  ...   \n","7405  135136897000415233     1     1     0    1     1     1    1   \n","7406  143471916534087680     1     1     0    1     1     0    1   \n","7407  153955345411219456     1     0     1    1     1     0    1   \n","7408  190835515552047104     1     1     0    1     1     1    0   \n","7409  193068210763993088     1     1     0    1     1     1    1   \n","\n","                                                   text  polarity  \n","0     Intanto la partita per Via Nazionale si compli...         1  \n","1     False illusioni, sgradevoli realtà Mario Monti...         1  \n","2     False illusioni, sgradevoli realtà #editoriale...         1  \n","3     Mario Monti: Berlusconi risparmi all'Italia il...         1  \n","4     Mario Monti: Berlusconi risparmi all'Italia il...         1  \n","...                                                 ...       ...  \n","7405  che ci frega di mario monti, noi abbiamo mario...         0  \n","7406  Strepitoso il titolo in prima di Libero sul go...         0  \n","7407  @nataliacavalli Consolati, il governo #Monti h...         1  \n","7408  @SheisCandida beh, beate loro! Io nn possiedo ...         0  \n","7409  Caro #Renzi,se #Grillo spaccava i computer e o...         0  \n","\n","[7410 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-821f6516-c2e2-4bc1-a1ec-7e3d6e2cd898\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idtwitter</th>\n","      <th>subj</th>\n","      <th>opos</th>\n","      <th>oneg</th>\n","      <th>iro</th>\n","      <th>lpos</th>\n","      <th>lneg</th>\n","      <th>top</th>\n","      <th>text</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>122449983151669248</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Intanto la partita per Via Nazionale si compli...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>125485104863780865</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>False illusioni, sgradevoli realtà Mario Monti...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>125513454315507712</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>False illusioni, sgradevoli realtà #editoriale...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>125524238290522113</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>125527933224886272</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7405</th>\n","      <td>135136897000415233</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>che ci frega di mario monti, noi abbiamo mario...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7406</th>\n","      <td>143471916534087680</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Strepitoso il titolo in prima di Libero sul go...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7407</th>\n","      <td>153955345411219456</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>@nataliacavalli Consolati, il governo #Monti h...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7408</th>\n","      <td>190835515552047104</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@SheisCandida beh, beate loro! Io nn possiedo ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7409</th>\n","      <td>193068210763993088</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Caro #Renzi,se #Grillo spaccava i computer e o...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7410 rows × 10 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-821f6516-c2e2-4bc1-a1ec-7e3d6e2cd898')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-821f6516-c2e2-4bc1-a1ec-7e3d6e2cd898 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-821f6516-c2e2-4bc1-a1ec-7e3d6e2cd898');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"JKq0Eo5pZINH","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1656085397346,"user_tz":-120,"elapsed":194,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"f754c946-3214-40b0-a9f5-acd8b3917176"},"source":["test_df"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               idtwitter  subj  opos  oneg  iro  lpos  lneg  top  \\\n","0     507074506880712705     0     0     0    0     0     0    2   \n","1     507075789456961536     1     1     0    0     1     0    2   \n","2     507077511902425088     1     0     1    0     0     1    2   \n","3     507079183315787777     0     0     0    0     0     0    2   \n","4     507080190225563648     1     0     0    0     0     0    2   \n","...                  ...   ...   ...   ...  ...   ...   ...  ...   \n","1993  645372190645481472     0     0     0    0     0     0    0   \n","1994  645628412225265664     0     0     0    0     0     0    0   \n","1995  645919232367161344     1     1     1    0     1     1    0   \n","1996  648567080107790336     1     0     1    0     0     1    0   \n","1997  648595040999239680     1     1     0    0     1     0    0   \n","\n","                                                   text  polarity  \n","0     Tra 5 minuti presentazione piano scuola del go...         3  \n","1     \\@matteorenzi: Alle 10 appuntamento su http://...         0  \n","2     #labuonascuola gli #evangelisti #digitali non ...         1  \n","3     Riforma scuola Tutto il discorso di  Renzi su ...         3  \n","4     .@matteorenzi @MiurSocial #labuonascuola basta...         3  \n","...                                                 ...       ...  \n","1993  Anche prodotti alimentari tipici pugliesi in v...         3  \n","1994         intensità di vita  https://t.co/jv4aARxzhz         3  \n","1995  Oggi tutti che iniziano l'università e io sul ...         2  \n","1996  @GliIntoccabili @nonleggerlo Ma Ferrero? il co...         1  \n","1997  Non vedi l'ora che venga qui, almeno lo sentir...         0  \n","\n","[1998 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-edc55532-76b7-4a12-9242-65888d772157\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idtwitter</th>\n","      <th>subj</th>\n","      <th>opos</th>\n","      <th>oneg</th>\n","      <th>iro</th>\n","      <th>lpos</th>\n","      <th>lneg</th>\n","      <th>top</th>\n","      <th>text</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>507074506880712705</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Tra 5 minuti presentazione piano scuola del go...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>507075789456961536</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>\\@matteorenzi: Alle 10 appuntamento su http://...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>507077511902425088</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>#labuonascuola gli #evangelisti #digitali non ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>507079183315787777</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Riforma scuola Tutto il discorso di  Renzi su ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>507080190225563648</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>.@matteorenzi @MiurSocial #labuonascuola basta...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1993</th>\n","      <td>645372190645481472</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Anche prodotti alimentari tipici pugliesi in v...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1994</th>\n","      <td>645628412225265664</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>intensità di vita  https://t.co/jv4aARxzhz</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>645919232367161344</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Oggi tutti che iniziano l'università e io sul ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1996</th>\n","      <td>648567080107790336</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@GliIntoccabili @nonleggerlo Ma Ferrero? il co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1997</th>\n","      <td>648595040999239680</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Non vedi l'ora che venga qui, almeno lo sentir...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1998 rows × 10 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edc55532-76b7-4a12-9242-65888d772157')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-edc55532-76b7-4a12-9242-65888d772157 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-edc55532-76b7-4a12-9242-65888d772157');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"IKtA4i770zCe","executionInfo":{"status":"ok","timestamp":1656085407010,"user_tz":-120,"elapsed":187,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["# Export text for statistics generation\n","try:\n","    os.mkdir('texts')\n","except OSError:\n","    print (\"Creation of the directory failed\")\n","\n","np.savetxt(r'texts/train_texts.txt', train_df[\"text\"].values, fmt='%s')\n","np.savetxt(r'texts/test_texts.txt', test_df[\"text\"].values, fmt='%s')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"v1hP-okE2QUX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656085427196,"user_tz":-120,"elapsed":1247,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"23490d0a-e9b6-480d-a259-74c3652283bb"},"source":["# Generate word statistics\n","! python /content/ekphrasis/ekphrasis/tools/generate_stats.py --input /content/texts/ --name sentipolc16 --ngrams 2 --mincount 70 30"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","computing statistics for file:  /content/texts/test_texts.txt\n","\r1/2:   0% 0/2000 [00:00<?, ?it/s]\r1/2: 100% 2000/2000 [00:00<00:00, 52798.39it/s]\n","\n","Writing 1-grams...\n","entries:5,113\t-\ttokens:23,701\n","writing stats to file /content/ekphrasis/ekphrasis/tools/../stats/sentipolc16/counts_1grams.txt\n","Writing 2-grams...\n","entries:16,209\t-\ttokens:23,701\n","writing stats to file /content/ekphrasis/ekphrasis/tools/../stats/sentipolc16/counts_2grams.txt\n","\n","computing statistics for file:  /content/texts/train_texts.txt\n","2/2: 100% 7410/7410 [00:00<00:00, 50606.52it/s]\n","\n","Writing 1-grams...\n","entries:15,813\t-\ttokens:120,654\n","writing stats to file /content/ekphrasis/ekphrasis/tools/../stats/sentipolc16/counts_1grams.txt\n","Writing 2-grams...\n","entries:68,281\t-\ttokens:120,654\n","writing stats to file /content/ekphrasis/ekphrasis/tools/../stats/sentipolc16/counts_2grams.txt\n","\n","Writing 1-grams...\n","entries:4,171\t-\ttokens:106,708\n","writing stats to file /content/ekphrasis/ekphrasis/tools/../stats/sentipolc16/counts_1grams.txt\n","Writing 2-grams...\n","entries:5,979\t-\ttokens:51,943\n","writing stats to file /content/ekphrasis/ekphrasis/tools/../stats/sentipolc16/counts_2grams.txt\n"]}]},{"cell_type":"code","metadata":{"id":"cHHN0U3Hnl3y","executionInfo":{"status":"ok","timestamp":1656085442176,"user_tz":-120,"elapsed":198,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["# Create lists with text and polarity columns\n","train_texts = train_df[\"text\"].tolist()\n","train_labels = train_df[\"polarity\"].tolist()\n","\n","test_texts = test_df[\"text\"].tolist()\n","test_labels = test_df[\"polarity\"].tolist()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwRf_Ale_jtP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656085502451,"user_tz":-120,"elapsed":31660,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"cfd29126-1f71-473a-9368-41325e22c03d"},"source":["# Define a preprocessing pipeline with ekphrasis\n","\n","text_processor = TextPreProcessor(\n","    # terms that will be normalized\n","    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n","        'time', 'date', 'number'],\n","    # terms that will be annotated\n","    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\", 'emphasis', 'censored'},\n","    annotate={\"hashtag\"},\n","    fix_html=True,  # fix HTML tokens\n","    \n","    # corpus from which the word statistics are going to be used \n","    # for word segmentation \n","    #segmenter=\"twitter\", \n","    #segmenter = Segmenter(corpus=\"sentipolc16\"),\n","    \n","    # corpus from which the word statistics are going to be used \n","    # for spell correction\n","    #corrector=\"twitter\", \n","    \n","    unpack_hashtags=True,  # perform word segmentation on hashtags\n","    #unpack_contractions=True,  # Unpack contractions (can't -> can not)\n","    #spell_correct_elong=False,  # spell correction for elongated words\n","    \n","    # select a tokenizer. You can use SocialTokenizer, or pass your own\n","    # the tokenizer, should take as input a string and return a list of tokens\n","    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n","    \n","    # list of dictionaries, for replacing tokens extracted from the text,\n","    # with other expressions. You can pass more than one dictionaries.\n","    dicts=[emoticons]\n",")\n","\n","def preprocess(text, do_lower_case=True):\n","    if do_lower_case:\n","        text = text.lower()\n","    text = str(\" \".join(text_processor.pre_process_doc(text)))\n","    text = re.sub(r'[^a-zA-ZÀ-ú</>!?♥♡\\s\\U00010000-\\U0010ffff]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', text)\n","    text = re.sub(r'^\\s', '', text)\n","    text = re.sub(r'\\s$', '', text)\n","    \n","    return text\n","\n","clean_train_texts = []\n","clean_test_texts = []\n","\n","for text in train_texts:\n","    #print(\" \".join(text_processor.pre_process_doc(text)))\n","    #clean_train_texts.append(\" \".join(text_processor.pre_process_doc(text)))\n","    clean_train_texts.append(preprocess(text))\n","\n","for text in test_texts:\n","    #print(\" \".join(text_processor.pre_process_doc(text)))\n","    #clean_test_texts.append(\" \".join(text_processor.pre_process_doc(text)))\n","    clean_test_texts.append(preprocess(text))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n","  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"]},{"output_type":"stream","name":"stdout","text":["Word statistics files not found!\n","Downloading... done!\n","Unpacking... done!\n","Reading english - 1grams ...\n","generating cache file for faster loading...\n","reading ngrams /root/.ekphrasis/stats/english/counts_1grams.txt\n","Reading english - 2grams ...\n","generating cache file for faster loading...\n","reading ngrams /root/.ekphrasis/stats/english/counts_2grams.txt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n","  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"]},{"output_type":"stream","name":"stdout","text":["Reading english - 1grams ...\n"]}]},{"cell_type":"code","metadata":{"id":"V9aiyVGccWJ4","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1656085506273,"user_tz":-120,"elapsed":190,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"37e6e719-02e9-4635-e616-568aba8e8a37"},"source":["train_texts[2]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'False illusioni, sgradevoli realtà #editoriale di Mario Monti sul Corriere della Sera: http://t.co/2jPxX6Jm #rassegna stampa'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"JYFMtfk7bJgI","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1656085511858,"user_tz":-120,"elapsed":192,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"bd9d847b-c797-4278-a75a-c1d75ba6c636"},"source":["clean_train_texts[2]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'false illusioni sgradevoli realtà <hashtag> editoriale </hashtag> di mario monti sul corriere della sera <url> <hashtag> rassegna </hashtag> stampa'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"bicrFeRww3tz","executionInfo":{"status":"ok","timestamp":1656085526035,"user_tz":-120,"elapsed":211,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["train_texts = clean_train_texts\n","test_texts = clean_test_texts"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Save the processed version of the datasets (useful for other operations, optional)."],"metadata":{"id":"wy5ulXsYxW0D"}},{"cell_type":"code","source":["train_df[\"text\"] = train_texts\n","test_df[\"text\"] = test_texts"],"metadata":{"id":"uskWkfypxkYn","executionInfo":{"status":"ok","timestamp":1656085529793,"user_tz":-120,"elapsed":205,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#train_df.to_csv('sentipolc_train_set_preprocessed.csv', index=False)\n","#!cp -r '/content/sentipolc_train_set_preprocessed.csv' /content/gdrive/MyDrive/\n","\n","test_df.to_csv('sentipolc_test_set_preprocessed.csv', index=False)\n","!cp -r '/content/sentipolc_test_set_preprocessed.csv' /content/gdrive/MyDrive/"],"metadata":{"id":"IWzuVXnSx1a2","executionInfo":{"status":"ok","timestamp":1656085532054,"user_tz":-120,"elapsed":513,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ssKH6o0e3r2y"},"source":["## Define the model"]},{"cell_type":"code","metadata":{"id":"XHMdFNdA1DSG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656085537189,"user_tz":-120,"elapsed":204,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"428032e8-4933-4171-83e4-f071228b033a"},"source":["# Set random seed and set device to GPU.\n","torch.manual_seed(0)\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda:0')\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","else:\n","    device = torch.device('cpu')\n","\n","print(device)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"lzSVz6ktpve7"},"source":["Create tokenizer and pretrained AlBERTo model. For further details on AlBERTo see [here](https://github.com/marcopoli/AlBERTo-it)."]},{"cell_type":"code","metadata":{"id":"u6_ek_kwox2d","colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["ed8353f0b5cc4be3a7ea433a49078196","73801364b99a4bf6bf348744f5102de1","7108c2cc115b445db02816f392b736d9","aa98d81fab344268b23add3112e31931","06f9a05fcdd94dbcab3e8599f483afd4","a3b2aa8834e249679ba167c4c06ce258","fa54e73fde30449fb95824b8b708392f","b27d14fc1a00434abf5e3d8600da4302","5a7e27e70dc64da4b058e0b690cd84a6","768468e0523a4393bebe45ea7728416d","fdf88b1b70bc4e828d8aae1443461723","9be802c08d8b4f3293285a2609b0215f","70ec195a2dbd471d828f3c6426b23449","fd5e8f5ae68d40d4a6b7b04d10aa48f1","b9598a5d503d481992ce947f19bdb5d9","c253dc9f840642dbb4b15bceb4a22125","747aef9b9aea445fa2ee05504c5792e0","14fde2e40a724315b36fcd35dbc648d6","dad31ff41a554967b3565e2f5541f68c","18f24fa5878f4f09bd3bd31b98a9b532","be6c3e1b95cc43a597a6dfff6c7e286c","d0b51467f98143cfb8513e560b82ee6b","e8425da9d34541fbb5d74ddffaea20ea","0a66f11ed9b243fd853a1493852e9119","f9956895145d49318cb6f86a7a3878cf","c0f6e6bca578455d8672dc7bb2b7bf3f","b02e1c9a58d34864b7174ac4beba8b91","7c56d0ecfe73490399b442bd81c68cf9","72f52216d1fa4244bef724efd54b316c","2bde39752e0c44ecbe6bcb43b1f02dc6","44b4730f75e1455ebd06a4966f2bc94a","b09a1c4a30724bacbcf2b3f7115b92f0","e65882bbf9c043d78d2d007efc71e52e"]},"executionInfo":{"status":"ok","timestamp":1656085700475,"user_tz":-120,"elapsed":22487,"user":{"displayName":"colab colab","userId":"03073534619707860702"}},"outputId":"dfc3308c-9603-45aa-83d2-9ec1a17a0035"},"source":["# Create tokenizer and pretrained umberto model\n","#tokenizer = AutoTokenizer.from_pretrained(\"Musixmatch/umberto-commoncrawl-cased-v1\")\n","#model = AutoModelForSequenceClassification.from_pretrained(\"Musixmatch/umberto-commoncrawl-cased-v1\", num_labels = 4)\n","\n","# Create tokenizer and pretrained alberto model\n","tokenizer = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\", num_labels=4)\n","\n","#model = AutoModelForSequenceClassification.from_pretrained(\"Musixmatch/umberto-commoncrawl-cased-v1\", num_labels = 2)\n","\n","#tokenizer = AutoTokenizer.from_pretrained(\"Musixmatch/umberto-wikipedia-uncased-v1\")\n","#model = AutoModelForSequenceClassification.from_pretrained(\"Musixmatch/umberto-wikipedia-uncased-v1\", \n","#                                                           num_labels = 4,\n","                                                           #attention_probs_dropout_prob=0.2,\n","                                                           #hidden_dropout_prob=0.4\n","#                                                           )"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8353f0b5cc4be3a7ea433a49078196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be802c08d8b4f3293285a2609b0215f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/706M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8425da9d34541fbb5d74ddffaea20ea"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["In this cell we create a custom model based on AlBERTo, skip this cell if you want to perform fine tuning on the base AlBERTo model "],"metadata":{"id":"k4QwtsOgL306"}},{"cell_type":"code","metadata":{"id":"Gzoyv63tP65Z"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n","\n","class SAModel(nn.Module):\n","    def __init__(self, dropout_rate=0.1, num_labels=4):\n","        super(SAModel, self).__init__()\n","        \n","        self.bert = AutoModel.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n","\n","        self.dropout1 = nn.Dropout(dropout_rate)\n","        self.linear1 = nn.Linear(768, 384)\n","        self.ln1 = nn.LayerNorm(384)\n","        \n","        self.dropout2 = nn.Dropout(dropout_rate)\n","        self.linear2 = nn.Linear(384, 64)\n","        self.ln2 = nn.LayerNorm(64)\n","        \n","        self.dropout3 = nn.Dropout(dropout_rate)\n","        self.linear3 = nn.Linear(64, num_labels)\n","        \n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","\n","        outputs = self.dropout1(outputs[0][:,0,:].view(-1,768))\n","        outputs = self.linear1(outputs)\n","        outputs = self.ln1(outputs)\n","        outputs = torch.nn.Tanh()(outputs)\n","        \n","        outputs = self.dropout2(outputs)\n","        outputs = self.linear2(outputs)\n","        outputs = self.ln2(outputs)\n","        outputs = torch.nn.Tanh()(outputs)\n","\n","        outputs = self.dropout3(outputs)\n","        outputs = self.linear3(outputs)\n","        \n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBHv_lIHtcbE"},"source":["# Only for the custom model\n","model = SAModel().to('cuda')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTBpmAMvqWbB","executionInfo":{"status":"ok","timestamp":1656085707743,"user_tz":-120,"elapsed":765,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["# Tokenize texts\n","train_encodings = tokenizer(train_texts, padding=True)\n","test_encodings = tokenizer(test_texts, padding=True)"],"execution_count":24,"outputs":[]},{"cell_type":"code","source":["train_encodings['attention_mask']"],"metadata":{"id":"IWShwzIfZc6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKvSE4gotVQ5","executionInfo":{"status":"ok","timestamp":1656086004555,"user_tz":-120,"elapsed":237,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["# Turn our labels and encodings into a Dataset object\n","\n","class TextDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = TextDataset(train_encodings, train_labels)\n","test_dataset = TextDataset(test_encodings, test_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"-EYrBxV8akNC"},"source":["# Freeze some layers (optional)\n","freeze_layers = \"5,6,7,8,9,10,11\"\n","\n","if freeze_layers is not \"\":\n","        layer_indexes = [int(x) for x in freeze_layers.split(\",\")]\n","        for layer_idx in layer_indexes:\n","             for param in list(model.roberta.encoder.layer[layer_idx].parameters()):\n","                 param.requires_grad = False\n","             print (\"Froze Layer: \", layer_idx)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PHtGPyts5fKM"},"source":["## Fine-tuning in native PyTorch"]},{"cell_type":"code","metadata":{"id":"9JYWlYeRWolA"},"source":["# Functions for saving and loading model parameters and metrics.\n","def save_checkpoint(path, model, valid_loss):\n","    torch.save({'model_state_dict': model.state_dict(),\n","                  'valid_loss': valid_loss}, path)\n","\n","    \n","def load_checkpoint(path, model):    \n","    state_dict = torch.load(path, map_location=device)\n","    model.load_state_dict(state_dict['model_state_dict'])\n","    \n","    return state_dict['valid_loss']\n","\n","\n","def save_metrics(path, train_loss_list, valid_loss_list, global_steps_list):   \n","    state_dict = {'train_loss_list': train_loss_list,\n","                  'valid_loss_list': valid_loss_list,\n","                  'global_steps_list': global_steps_list}\n","    \n","    torch.save(state_dict, path)\n","\n","\n","def load_metrics(path):    \n","    state_dict = torch.load(path, map_location=device)\n","    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYwHMWE-k4SW"},"source":["# Pre-training function with Pytorch\n","\n","def pretrain(model,\n","            optimizer,\n","            train_loader,\n","            valid_loader,\n","            num_epochs,\n","            output_path,\n","            valid_period,\n","            scheduler=None):\n","\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    # Pretrain linear layers, do not train bert\n","    #for param in model.roberta.parameters():\n","    for param in model.bert.parameters():\n","        param.requires_grad = False\n","\n","    model.train()\n","\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    global_step = 0\n","    \n","    for epoch in range(num_epochs):\n","        for batch_train in train_loader:\n","\n","            optim.zero_grad()\n","\n","            input_ids = batch_train['input_ids'].to(device)\n","            attention_mask = batch_train['attention_mask'].to(device)\n","            labels = batch_train['labels'].to(device)\n","        \n","            outputs = model(input_ids, attention_mask=attention_mask)\n","\n","            loss = nn.CrossEntropyLoss()(outputs,labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            train_loss += loss.item()\n","            global_step += 1\n","        \n","            if global_step % valid_period == 0:\n","                model.eval()\n","\n","                with torch.no_grad():\n","                    for batch_eval in valid_loader:\n","\n","                        input_ids = batch_eval['input_ids'].to(device)\n","                        attention_mask = batch_eval['attention_mask'].to(device)\n","                        labels = batch_eval['labels'].to(device)\n","\n","                        outputs = model(input_ids, attention_mask=attention_mask)\n","\n","                        loss = nn.CrossEntropyLoss()(outputs,labels)\n","\n","                        valid_loss += loss.item()\n","      \n","                train_loss = train_loss / valid_period\n","                valid_loss = valid_loss / len(valid_loader)\n","                \n","                model.train()\n","\n","                # print summary\n","                print('Epoch [{}/{}], global step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n","                      .format(epoch+1, num_epochs, global_step, num_epochs*valid_period,\n","                              train_loss, valid_loss))\n","                                      \n","                train_loss = 0.0                \n","                valid_loss = 0.0\n","\n","    # Set bert parameters back to trainable\n","    #for param in model.roberta.parameters():\n","    for param in model.bert.parameters():\n","        param.requires_grad = True\n","\n","    print('Pre-training done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qVgkn-6pWi1B"},"source":["# Training function with Pytorch\n","\n","def train(model,\n","          optimizer,\n","          train_loader,\n","          valid_loader,\n","          num_epochs,\n","          output_path,\n","          valid_period,\n","          scheduler=None):\n","\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    train_loss_list = []\n","    valid_loss_list = []\n","    best_valid_loss = float('Inf')\n","\n","    global_step = 0\n","    global_steps_list = []\n","\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    model.train()\n","\n","    for epoch in range(num_epochs):\n","        for batch_train in train_loader:\n","\n","            optim.zero_grad()\n","\n","            input_ids = batch_train['input_ids'].to(device)\n","            attention_mask = batch_train['attention_mask'].to(device)\n","            labels = batch_train['labels'].to(device)\n","        \n","            outputs = model(input_ids, attention_mask=attention_mask)\n","\n","            loss = nn.CrossEntropyLoss()(outputs,labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            train_loss += loss.item()\n","            global_step += 1\n","        \n","            if global_step % valid_period == 0:\n","                model.eval()\n","\n","                with torch.no_grad():\n","                    for batch_eval in valid_loader:\n","                        input_ids = batch_eval['input_ids'].to(device)\n","                        attention_mask = batch_eval['attention_mask'].to(device)\n","                        labels = batch_eval['labels'].to(device)\n","\n","                        outputs = model(input_ids, attention_mask=attention_mask)\n","\n","                        loss = nn.CrossEntropyLoss()(outputs,labels)\n","\n","                        valid_loss += loss.item()\n","      \n","                train_loss = train_loss / valid_period\n","                valid_loss = valid_loss / len(valid_loader)\n","                train_loss_list.append(train_loss)\n","                valid_loss_list.append(valid_loss)\n","                global_steps_list.append(global_step)\n","\n","                # print summary\n","                print('Epoch [{}/{}], global step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n","                      .format(epoch+1, num_epochs, global_step, num_epochs*valid_period,\n","                              train_loss, valid_loss))\n","                \n","                # checkpoint\n","                if best_valid_loss > valid_loss:\n","                    best_valid_loss = valid_loss\n","                    save_checkpoint(output_path + '/model.pt', model, best_valid_loss)\n","                    save_metrics(output_path + '/metric.pt', train_loss_list, valid_loss_list, global_steps_list)\n","                        \n","                train_loss = 0.0                \n","                valid_loss = 0.0\n","                model.train()\n","\n","    save_metrics(output_path + '/metric.pt', train_loss_list, valid_loss_list, global_steps_list)\n","    print('Training done!')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jymux4bXpt7n"},"source":["model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PY4c_N6X5XJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643204876590,"user_tz":-60,"elapsed":759024,"user":{"displayName":"Tommaso Ceccarini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16326510516918191196"}},"outputId":"51b7cbca-e603-4253-eccf-edc55f3eacaf"},"source":["# Fine-tuning with Pytorch\n","\n","output_path = '/content'\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","valid_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","\n","print(\"Start pretraining\")\n","\n","num_epochs = 3\n","\n","optim = AdamW(model.parameters(), lr=1e-4)\n","scheduler = get_linear_schedule_with_warmup(optim, \n","                                            num_warmup_steps=len(train_loader)*1, \n","                                            num_training_steps=len(train_loader)*num_epochs)\n","\n","pretrain(model=model,\n","         optimizer=optim,\n","         train_loader=train_loader,\n","         valid_loader=valid_loader,\n","         num_epochs=num_epochs,\n","         output_path=output_path,\n","         valid_period=len(train_loader),\n","         scheduler=scheduler\n","         )\n","\n","print(\"Start training\")\n","\n","num_epochs = 3\n","\n","optim = AdamW(model.parameters(), lr=2e-5)\n","scheduler = get_linear_schedule_with_warmup(optim, \n","                                            num_warmup_steps=len(train_loader)*2, \n","                                            num_training_steps=len(train_loader)*num_epochs)\n","\n","train(model=model,\n","      optimizer=optim,\n","      train_loader=train_loader,\n","      valid_loader=valid_loader,\n","      num_epochs=num_epochs,\n","      output_path=output_path,\n","      valid_period=len(train_loader),\n","      scheduler=scheduler\n","      )\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start pretraining\n","Epoch [1/3], global step [232/696], Train Loss: 1.2134, Valid Loss: 1.0054\n","Epoch [2/3], global step [464/696], Train Loss: 1.1086, Valid Loss: 0.9688\n","Epoch [3/3], global step [696/696], Train Loss: 1.0693, Valid Loss: 0.9351\n","Pre-training done!\n","Start training\n","Epoch [1/3], global step [232/696], Train Loss: 0.9743, Valid Loss: 0.9037\n","Epoch [2/3], global step [464/696], Train Loss: 0.8202, Valid Loss: 0.9187\n","Epoch [3/3], global step [696/696], Train Loss: 0.6169, Valid Loss: 0.9401\n","Training done!\n"]}]},{"cell_type":"code","metadata":{"id":"pWWN7AvPS1py","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643203903173,"user_tz":-60,"elapsed":741,"user":{"displayName":"Tommaso Ceccarini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16326510516918191196"}},"outputId":"ede7523b-ae8b-44ae-8cf5-f9a6773631cc"},"source":["# Load best model\n","device = torch.device('cuda:0')\n","load_checkpoint(output_path + '/model.pt', model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.855774539232254"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"Ao5mss3svSRy"},"source":["# Evaluate model with Pytorch\n","\n","y_pred = []\n","y_true = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for batch_eval in valid_loader:\n","        input_ids = batch_eval['input_ids'].to(device)\n","        attention_mask = batch_eval['attention_mask'].to(device)\n","        labels = batch_eval['labels'].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","\n","        y_pred.extend(torch.argmax(outputs, axis=-1).tolist())\n","        #y_pred.extend(torch.argmax(outputs[0], axis=-1).tolist())\n","        y_true.extend(labels.tolist())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKSL9H6dyfSO"},"source":["print(classification_report(y_true, y_pred, labels=[0, 1, 2, 3]))\n","\n","cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n","ax = plt.subplot()\n","\n","sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n","\n","ax.set_title('Confusion Matrix')\n","\n","ax.set_xlabel('Predicted Labels')\n","ax.set_ylabel('True Labels')\n","\n","ax.xaxis.set_ticklabels(['Positive', 'Negative', 'Mixed', 'Neutral'])\n","ax.yaxis.set_ticklabels(['Positive', 'Negative', 'Mixed', 'Neutral'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"92ih1CLz1Usr"},"source":["# Save fine-tuned model\n","torch.save(model,'/content/model_6_pre_1_ep_32_bs_4_nc.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"38dUQJn75ICC"},"source":["## Fine-tuning in PyTorch with the Trainer API"]},{"cell_type":"code","metadata":{"id":"kcX40w1WrTwy","executionInfo":{"status":"ok","timestamp":1656086033601,"user_tz":-120,"elapsed":15028,"user":{"displayName":"colab colab","userId":"03073534619707860702"}}},"source":["# Fine-tuning with Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=10,             # total number of training epochs\n","    per_device_train_batch_size=64,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    learning_rate=2e-5,             # the initial learning rate for AdamW optimizer\n","    #max_grad_norm=0.01,             # maximum gradient norm (for gradient clipping) \n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.1,                # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=25,\n","    save_strategy='epoch',            # save is done at the end of each epoch\n","    evaluation_strategy='epoch',      \n","    eval_steps='epoch',              # evaluation is done at the end of each epoch\n","    load_best_model_at_end=True      # whether or not to load the best model found during training at the end of training\n",")\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=test_dataset            # evaluation dataset\n",")\n","\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylT4NOW8SA0J"},"source":["# start training for fine-tuning with Trainer\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1XptoZG73HT","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["66011446a51d4017987d49fa37549952","82f9dc83c7044a5da6148a5514a2c75f","bb44b1f3b26645928cd89d37f072a74f","8b7c9255194a4f6b8bcd9f6ce9e4b4ad","a4e1245d3d6946db9580f4dbc25c7b49","ee0930c07dee43b1b6a0e04183f01ab3","0f1707e624c24adeb547180294185ca0","360aae05dbdb48f1976e30050121c056","2679c193580b47e4acd7ba4cf08122f4","77ad24d42c9c4913b8ccd8fce3c1c92f","6627ef562a2b4f6681280fa1e6e5624f","298fc44a495448658c036d084cf9bffa","44fdfc9473584aa6873aed33d9d66be9","335d51a8bdb348d7955276894ed6995e","5ebf3f9600d34afaa80bd3ec95c696d7","72db15492a1e43e19749cbdb4fdae7bc","4b3bf1f059964864a5a8966f02879510","0f26a55907664f2fa828a152d37f178f","6b7b718aa0c14065abe7390bc5bdbbda","7905c052029b4a72a27dd901cf1514ae","a17f948c1f314011b74a65f7eb1bde18","915cd4f21b4e462e9cd054f00732edde"]},"executionInfo":{"status":"ok","timestamp":1634316221722,"user_tz":-120,"elapsed":1221,"user":{"displayName":"Tommaso Ceccarini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16326510516918191196"}},"outputId":"c73cb542-0924-4802-a739-11263cdc5ef2"},"source":["# Compute metrics\n","\n","acc = load_metric(\"accuracy\")\n","f1 = load_metric(\"f1\")\n","\n","def compute_acc(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return acc.compute(predictions=predictions, references=labels)\n","\n","def compute_f1(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return f1.compute(predictions=predictions, references=labels, average='macro')\n","\n","trainer_acc = Trainer(\n","    model=model,\n","    args=training_args,\n","    #train_dataset=train_dataset,\n","    train_dataset=test_dataset,\n","    eval_dataset=test_dataset,\n","    compute_metrics=compute_acc,\n",")\n","\n","trainer_f1 = Trainer(\n","    model=model,\n","    args=training_args,\n","    #train_dataset=train_dataset,\n","    train_dataset=test_dataset,\n","    eval_dataset=test_dataset,\n","    compute_metrics=compute_f1,\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66011446a51d4017987d49fa37549952","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"298fc44a495448658c036d084cf9bffa","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"sIDJbxNqOYC9","colab":{"base_uri":"https://localhost:8080/","height":171},"executionInfo":{"status":"ok","timestamp":1634316251919,"user_tz":-120,"elapsed":25537,"user":{"displayName":"Tommaso Ceccarini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16326510516918191196"}},"outputId":"9cee4ebb-ee56-4f78-c63b-6a42e58d48dc"},"source":["trainer_acc.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1998\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 00:25]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_accuracy': 0.6456456456456456,\n"," 'eval_loss': 0.897082507610321,\n"," 'eval_runtime': 25.4566,\n"," 'eval_samples_per_second': 78.486,\n"," 'eval_steps_per_second': 4.91}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"LF9Z-XmaOTyF","colab":{"base_uri":"https://localhost:8080/","height":171},"executionInfo":{"status":"ok","timestamp":1634316285625,"user_tz":-120,"elapsed":25559,"user":{"displayName":"Tommaso Ceccarini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16326510516918191196"}},"outputId":"5e1817e4-f13d-463f-f7dd-f0286aeb88b8"},"source":["trainer_f1.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1998\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 00:25]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_f1': 0.48769559705789634,\n"," 'eval_loss': 0.897082507610321,\n"," 'eval_runtime': 25.3528,\n"," 'eval_samples_per_second': 78.808,\n"," 'eval_steps_per_second': 4.93}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"GlAkn84q47h_"},"source":["## Zip and download fine-tuned model"]},{"cell_type":"code","metadata":{"id":"80lS4Q3W1ck0"},"source":["# Zip and download results folder\n","\n","#Fine-tuning in native PyTorch\n","!zip -r /content/model.zip /content/model.pt\n","!cp -r '/content/model.zip' /content/gdrive/MyDrive/\n","\n","#Fine-tuning with the Trainer API\n","#!zip -r /content/results.zip /content/results\n","#!cp -r '/content/results.zip' /content/gdrive/MyDrive/\n"],"execution_count":null,"outputs":[]}]}